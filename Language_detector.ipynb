{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J6J79yfrB6sx",
        "outputId": "90b166c7-fc5c-4898-ccde-766c89386707"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "import re\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Defining the stopwords, symbols and punctuations list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {},
      "outputs": [],
      "source": [
        "#stopwords_hi = ['तुम','मेरी','मुझे','क्योंकि','हम','प्रति','अबकी','आगे','माननीय','शहर','बताएं','कौनसी','क्लिक','किसकी','बड़े','मैं','and','रही','आज','लें','आपके','मिलकर','सब','मेरे','जी','श्री','वैसा','आपका','अंदर', 'अत', 'अपना', 'अपनी', 'अपने', 'अभी', 'आदि', 'आप', 'इत्यादि', 'इन', 'इनका', 'इन्हीं', 'इन्हें', 'इन्हों', 'इस', 'इसका', 'इसकी', 'इसके', 'इसमें', 'इसी', 'इसे', 'उन', 'उनका', 'उनकी', 'उनके', 'उनको', 'उन्हीं', 'उन्हें', 'उन्हों', 'उस', 'उसके', 'उसी', 'उसे', 'एक', 'एवं', 'एस', 'ऐसे', 'और', 'कई', 'कर','करता', 'करते', 'करना', 'करने', 'करें', 'कहते', 'कहा', 'का', 'काफ़ी', 'कि', 'कितना', 'किन्हें', 'किन्हों', 'किया', 'किर', 'किस', 'किसी', 'किसे', 'की', 'कुछ', 'कुल', 'के', 'को', 'कोई', 'कौन', 'कौनसा', 'गया', 'घर', 'जब', 'जहाँ', 'जा', 'जितना', 'जिन', 'जिन्हें', 'जिन्हों', 'जिस', 'जिसे', 'जीधर', 'जैसा', 'जैसे', 'जो', 'तक', 'तब', 'तरह', 'तिन', 'तिन्हें', 'तिन्हों', 'तिस', 'तिसे', 'तो', 'था', 'थी', 'थे', 'दबारा', 'दिया', 'दुसरा', 'दूसरे', 'दो', 'द्वारा', 'न', 'नहीं', 'ना', 'निहायत', 'नीचे', 'ने', 'पर', 'पर', 'पहले', 'पूरा', 'पे', 'फिर', 'बनी', 'बही', 'बहुत', 'बाद', 'बाला', 'बिलकुल', 'भी', 'भीतर', 'मगर', 'मानो', 'मे', 'में', 'यदि', 'यह', 'यहाँ', 'यही', 'या', 'यिह', 'ये', 'रखें', 'रहा', 'रहे', 'ऱ्वासा', 'लिए', 'लिये', 'लेकिन', 'व', 'वर्ग', 'वह', 'वह', 'वहाँ', 'वहीं', 'वाले', 'वुह', 'वे', 'वग़ैरह', 'संग', 'सकता', 'सकते', 'सबसे', 'सभी', 'साथ', 'साबुत', 'साभ', 'सारा', 'से', 'सो', 'ही', 'हुआ', 'हुई', 'हुए', 'है', 'हैं', 'हो', 'होता', 'होती', 'होते', 'होना', 'होने', 'अपनि', 'जेसे', 'होति', 'सभि', 'तिंहों', 'इंहों', 'दवारा', 'इसि', 'किंहें', 'थि', 'उंहों', 'ओर', 'जिंहें', 'वहिं', 'अभि', 'बनि', 'हि', 'उंहिं', 'उंहें', 'हें', 'वगेरह', 'एसे', 'रवासा', 'कोन', 'निचे', 'काफि', 'उसि', 'पुरा', 'भितर', 'हे', 'बहि', 'वहां', 'कोइ', 'यहां', 'जिंहों', 'तिंहें', 'किसि', 'कइ', 'यहि', 'इंहिं', 'जिधर', 'इंहें', 'अदि', 'इतयादि', 'हुइ', 'कोनसा', 'इसकि', 'दुसरे', 'जहां', 'अप', 'किंहों', 'उनकि', 'भि', 'वरग', 'हुअ', 'जेसा', 'नहिं']\n",
        "symbols = {'~', ':', \"'\", '+', '[', '\\\\', '@', '^', '{', '%', '(', '-', '\"', '*', '|', ',', '&', '<', '`', '}', '.', '_', '=', ']', '!', '>', ';', '?', '#', '$', ')', '/','€','§' }\n",
        "punctuations=['\\u200d','\\xa0','\\t','\\n','|','।',':',';',',','.','\\'','\\\\','/','-','‘','’','(',')','?','[',']','*','+','“','”','!','…','+','{','}','=']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {},
      "outputs": [],
      "source": [
        "import re"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Preprocess function to be applied on every line of the dataset in order to clean/structure it"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {},
      "outputs": [],
      "source": [
        "def preprocess(line):\n",
        "    splits = line.split()\n",
        "    line = ' '.join(splits[1:-1])\n",
        "    for punc in punctuations:\n",
        "        line=line.replace(punc,\"\")\n",
        "    tmp = line.split()\n",
        "    tmp = [re.sub('[A-Za-z0-9]', '', word) for word in tmp]\n",
        "    return  ' '.join([word.strip() for word in tmp if not word.isnumeric() and word not in symbols ])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Creating a clean dataset to be used for training/testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {},
      "outputs": [],
      "source": [
        "final = []\n",
        "with open('hin_mixed_2019_1M-sentences.txt') as f:\n",
        "    \n",
        "    text = f.readlines()\n",
        "    for line in text:\n",
        "        if(len(final)==100000):\n",
        "            break\n",
        "        line = preprocess(line)\n",
        "        tmp = {}\n",
        "        tmp['sentence'] = line\n",
        "        tmp['language'] = \"hi\"\n",
        "        final.append(tmp)\n",
        "        \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(100000, 2)\n"
          ]
        }
      ],
      "source": [
        "df = pd.DataFrame(final)\n",
        "df.loc[:, 'sentence'] = df.loc[:,'sentence'].apply(lambda x: x.strip())\n",
        "print(df.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "          TF-IDF\n",
            "पदक     0.552704\n",
            "टर      0.442592\n",
            "पलच     0.380346\n",
            "तमग     0.343738\n",
            "रजत     0.305919\n",
            "लव      0.206939\n",
            "मध      0.206155\n",
            "वह      0.137801\n",
            "वर      0.132025\n",
            "रत      0.114927\n",
            "और      0.085286\n",
            "बरक     0.000000\n",
            "बरइल    0.000000\n",
            "बरईप    0.000000\n",
            "बरए     0.000000\n",
            "बरकर    0.000000\n",
            "बरकत    0.000000\n",
            "बरकतउल  0.000000\n",
            "बरख     0.000000\n",
            "बरग     0.000000\n",
            "बरगढ    0.000000\n",
            "बरगद    0.000000\n",
            "बर      0.000000\n",
            "बय      0.000000\n",
            "बयभ     0.000000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/joker/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        }
      ],
      "source": [
        "# import pandas as pd\n",
        "# from sklearn.feature_extraction.text import TfidfTransformer\n",
        "\n",
        "# dataset = list(df['sentence'])\n",
        "# tfIdfTransformer = TfidfTransformer(use_idf=True)\n",
        "# countVectorizer = CountVectorizer()\n",
        "# wordCount = countVectorizer.fit_transform(dataset)\n",
        "# newTfIdf = tfIdfTransformer.fit_transform(wordCount)\n",
        "# df1 = pd.DataFrame(newTfIdf[0].T.todense(), index=countVectorizer.get_feature_names(), columns=[\"TF-IDF\"])\n",
        "# df1 = df1.sort_values('TF-IDF', ascending=False)\n",
        "# print (df1.head(25))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {},
      "outputs": [],
      "source": [
        "from collections import Counter\n",
        "import math"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from nltk.tokenize import  word_tokenize "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {},
      "outputs": [],
      "source": [
        "data = list(df.sentence)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {},
      "outputs": [],
      "source": [
        "def extract_features( document ):\n",
        "   terms = tuple(document.lower().split())\n",
        "   features = set()\n",
        "   for i in range(len(terms)):\n",
        "      for n in range(1,2):\n",
        "          if i+n <= len(terms):\n",
        "              features.add(terms[i:i+n])\n",
        "   return features\n",
        "\n",
        "documents = [\n",
        "   \"This article is about the Golden State Warriors\",\n",
        "   \"This article is about the Golden Arches\",\n",
        "   \"This article is about state machines\",\n",
        "   \"This article is about viking warriors\"]\n",
        "\n",
        "def calculate_idf( documents ):\n",
        "   N = len(documents)\n",
        "   from collections import Counter\n",
        "   tD = Counter()\n",
        "   for d in documents:\n",
        "      features = extract_features(d)\n",
        "      for f in features:\n",
        "          tD[\" \".join(f)] += 1\n",
        "   IDF = []\n",
        "   import math\n",
        "   for (term,term_frequency) in tD.items():\n",
        "       term_IDF = math.log(float(N) / term_frequency)\n",
        "       IDF.append(( term_IDF, term ))\n",
        "   IDF.sort(reverse=True)\n",
        "   return IDF\n",
        "\n",
        "st = []\n",
        "for (IDF, term) in sorted(calculate_idf(data), key=lambda x: x[0])[:100]:\n",
        "    st.append(term)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['के',\n",
              " 'में',\n",
              " 'की',\n",
              " 'को',\n",
              " 'से',\n",
              " 'का',\n",
              " 'और',\n",
              " 'है',\n",
              " 'ने',\n",
              " 'पर',\n",
              " 'कि',\n",
              " 'भी',\n",
              " 'तो',\n",
              " 'नहीं',\n",
              " 'लिए',\n",
              " 'कर',\n",
              " 'अब',\n",
              " 'एक',\n",
              " 'ही',\n",
              " 'हैं',\n",
              " 'आप',\n",
              " 'हो',\n",
              " 'इस',\n",
              " 'अपने',\n",
              " 'आज',\n",
              " 'अगर',\n",
              " 'यह',\n",
              " 'करने',\n",
              " 'किया',\n",
              " 'तक',\n",
              " 'साथ',\n",
              " 'अपनी',\n",
              " 'रहे',\n",
              " 'गया',\n",
              " 'कहा',\n",
              " 'बाद',\n",
              " 'रहा',\n",
              " 'आपको',\n",
              " 'जो',\n",
              " 'जा',\n",
              " 'कुछ',\n",
              " 'हुए',\n",
              " 'कोई',\n",
              " 'रही',\n",
              " 'वह',\n",
              " 'या',\n",
              " 'दिया',\n",
              " 'बात',\n",
              " 'वाले',\n",
              " 'होने',\n",
              " 'किसी',\n",
              " 'करते',\n",
              " 'व',\n",
              " 'सकते',\n",
              " 'था',\n",
              " 'क्या',\n",
              " 'अभी',\n",
              " 'ये',\n",
              " 'पहले',\n",
              " 'हम',\n",
              " 'लोगों',\n",
              " 'न',\n",
              " 'भारत',\n",
              " 'लेकिन',\n",
              " 'गई',\n",
              " 'बहुत',\n",
              " 'सरकार',\n",
              " 'दिन',\n",
              " 'तरह',\n",
              " 'समय',\n",
              " 'देश',\n",
              " 'होता',\n",
              " 'जाता',\n",
              " 'आपके',\n",
              " 'काम',\n",
              " 'सकता',\n",
              " 'द्वारा',\n",
              " 'रूप',\n",
              " 'वाली',\n",
              " 'जब',\n",
              " 'करना',\n",
              " 'लेकर',\n",
              " 'साल',\n",
              " 'मैं',\n",
              " 'दी',\n",
              " 'गए',\n",
              " 'हुआ',\n",
              " 'उनके',\n",
              " 'लोग',\n",
              " 'दो',\n",
              " 'जाने',\n",
              " 'फिर',\n",
              " 'आ',\n",
              " 'उन्हें',\n",
              " 'वे',\n",
              " 'कई',\n",
              " 'करें',\n",
              " 'नाम',\n",
              " 'सभी',\n",
              " 'बार']"
            ]
          },
          "execution_count": 98,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "st"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {},
      "outputs": [],
      "source": [
        "def remove_stop(sent):\n",
        "    return \" \".join([w for w in sent.split() if w not in st])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {},
      "outputs": [],
      "source": [
        "df['sentence'] = df['sentence'].apply(lambda x: remove_stop(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>language</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>मीटर दौड स्वर्ण पदक मीटर दौड रजत पदक दिलाया वह...</td>\n",
              "      <td>hi</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>जन्म घटकर हैजो महत्वपूर्ण उपलब्धि</td>\n",
              "      <td>hi</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>जिस व्यक्ति तुमने मदद उसका आभार प्रकट करो उसे ...</td>\n",
              "      <td>hi</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ना मनुष्य ना भगवान विश्व अन्य दोष अच्छा प्रयत्न</td>\n",
              "      <td>hi</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>बदलाव नही</td>\n",
              "      <td>hi</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            sentence language\n",
              "0  मीटर दौड स्वर्ण पदक मीटर दौड रजत पदक दिलाया वह...       hi\n",
              "1                  जन्म घटकर हैजो महत्वपूर्ण उपलब्धि       hi\n",
              "2  जिस व्यक्ति तुमने मदद उसका आभार प्रकट करो उसे ...       hi\n",
              "3    ना मनुष्य ना भगवान विश्व अन्य दोष अच्छा प्रयत्न       hi\n",
              "4                                          बदलाव नही       hi"
            ]
          },
          "execution_count": 100,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Repeating the above steps with English Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /Users/joker/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 102,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {},
      "outputs": [],
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "sw = stopwords.words('english')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {},
      "outputs": [],
      "source": [
        "def preprocess_en(line):\n",
        "    splits = line.split()\n",
        "    line = ' '.join(splits[1:-1])\n",
        "    for punc in punctuations:\n",
        "        line=line.replace(punc,\"\")\n",
        "    tmp = line.split()\n",
        "    tmp = [re.sub('[0-9,\" ]', '', word) for word in tmp]\n",
        "    return  ' '.join([word.strip().lower() for word in tmp if word not in sw and not word.isnumeric() and word not in symbols ])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {},
      "outputs": [],
      "source": [
        "final = []\n",
        "with open('eng_news_2020_1M-sentences.txt') as f:\n",
        "    text = f.readlines()\n",
        "    for line in text:\n",
        "        if(len(final)==100000):\n",
        "            break\n",
        "        line = preprocess_en(line)\n",
        "        tmp = {}\n",
        "\n",
        "        tmp['sentence'] = line\n",
        "        tmp['language'] = \"en\"\n",
        "        final.append(tmp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(100000, 2)"
            ]
          },
          "execution_count": 108,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_en = pd.DataFrame(final)\n",
        "df_en.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>language</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>— nhl network  pm</td>\n",
              "      <td>en</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>spent advertising sans rare times see customer...</td>\n",
              "      <td>en</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>cash seized joint</td>\n",
              "      <td>en</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>hospice santa cruz county jacobs heart unantic...</td>\n",
              "      <td>en</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>£ bonus may enough protect</td>\n",
              "      <td>en</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>vouchers redeemed gozitan outlets accommodati...</td>\n",
              "      <td>en</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>upper target monthly</td>\n",
              "      <td>en</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>kwp solar hybrid minigrid bed ikenne isolation...</td>\n",
              "      <td>en</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>adults data ends credit scoring</td>\n",
              "      <td>en</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>four pack reserved picnic</td>\n",
              "      <td>en</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>100 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             sentence language\n",
              "0                                  — nhl network  pm        en\n",
              "1   spent advertising sans rare times see customer...       en\n",
              "2                                   cash seized joint       en\n",
              "3   hospice santa cruz county jacobs heart unantic...       en\n",
              "4                          £ bonus may enough protect       en\n",
              "..                                                ...      ...\n",
              "95   vouchers redeemed gozitan outlets accommodati...       en\n",
              "96                               upper target monthly       en\n",
              "97  kwp solar hybrid minigrid bed ikenne isolation...       en\n",
              "98                    adults data ends credit scoring       en\n",
              "99                          four pack reserved picnic       en\n",
              "\n",
              "[100 rows x 2 columns]"
            ]
          },
          "execution_count": 109,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_en.head(100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_en['sentence'] = df_en['sentence'].str.encode('ascii', 'ignore').str.decode('ascii')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Merging the two dataframes and shuffling the data points"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/6t/snv12c4s0z946pr0z8v_br280000gn/T/ipykernel_5826/1955524980.py:1: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  df_new = df.append(df_en)\n"
          ]
        }
      ],
      "source": [
        "df_new = df.append(df_en)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>language</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>बालों रंग बदल</td>\n",
              "      <td>hi</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>artists concerned paintings executed directly ...</td>\n",
              "      <td>en</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>पानी अधिक अधिक मात्रा</td>\n",
              "      <td>hi</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>अपना नेटवर्क लश्कर हिजबुल जैश सिमी फैलाता हज स...</td>\n",
              "      <td>hi</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>अन्त कहूँगा भगवान चाहा</td>\n",
              "      <td>hi</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>199995</th>\n",
              "      <td>आगे शैतान कहते उसको गॉड</td>\n",
              "      <td>hi</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>199996</th>\n",
              "      <td>a changing market rising costs title acquisiti...</td>\n",
              "      <td>en</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>199997</th>\n",
              "      <td>मसीही विश्वास होकर मनुष्य परमेश्वर मेलमिलाप मन...</td>\n",
              "      <td>hi</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>199998</th>\n",
              "      <td>उच्चतम न्यायालय आदेश अधिकारियों नोएडा सेक्टर स...</td>\n",
              "      <td>hi</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>199999</th>\n",
              "      <td>all express lanes blocked inbound dan ryan exp...</td>\n",
              "      <td>en</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>200000 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                 sentence language\n",
              "0                                           बालों रंग बदल       hi\n",
              "1       artists concerned paintings executed directly ...       en\n",
              "2                                   पानी अधिक अधिक मात्रा       hi\n",
              "3       अपना नेटवर्क लश्कर हिजबुल जैश सिमी फैलाता हज स...       hi\n",
              "4                                  अन्त कहूँगा भगवान चाहा       hi\n",
              "...                                                   ...      ...\n",
              "199995                            आगे शैतान कहते उसको गॉड       hi\n",
              "199996  a changing market rising costs title acquisiti...       en\n",
              "199997  मसीही विश्वास होकर मनुष्य परमेश्वर मेलमिलाप मन...       hi\n",
              "199998  उच्चतम न्यायालय आदेश अधिकारियों नोएडा सेक्टर स...       hi\n",
              "199999  all express lanes blocked inbound dan ryan exp...       en\n",
              "\n",
              "[200000 rows x 2 columns]"
            ]
          },
          "execution_count": 112,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_new = df_new.sample(frac=1, random_state=1)\n",
        "df_new.reset_index(drop=True, inplace=True)\n",
        "df_new"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Training, testing and doing some predictions on MNB model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "metadata": {
        "id": "Z7FJz4xPEvDs"
      },
      "outputs": [],
      "source": [
        "x = np.array(df_new[\"sentence\"])\n",
        "y = np.array(df_new[\"language\"])\n",
        "\n",
        "cv = CountVectorizer()\n",
        "X = cv.fit_transform(x)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
        "                                                    test_size=0.2, \n",
        "                                                    random_state=27)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u0k5bTEfFgHJ",
        "outputId": "f44ebeee-915b-48e0-a6e5-61f8e7033fec"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.999975"
            ]
          },
          "execution_count": 114,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = MultinomialNB()\n",
        "model.fit(X_train,y_train)\n",
        "model.score(X_test,y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d-5A5RWtFn6n",
        "outputId": "f2ade163-36a4-4845-d65d-6c0b1875d7ef"
      },
      "outputs": [],
      "source": [
        "# user = input(\"Enter a Text: \")\n",
        "# data = cv.transform([user]).toarray()\n",
        "# output = model.predict(data)\n",
        "# print(output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "mera ['en']\n",
            "naam ['en']\n",
            "is ['en']\n",
            "there ['en']\n",
            "he ['en']\n",
            "she ['en']\n",
            "hum ['en']\n",
            "humko ['hi']\n",
            "\n",
            "tera ['en']\n",
            "yours ['hi']\n",
            "mine ['en']\n",
            "\n",
            "why ['en']\n",
            "so ['en']\n",
            "cool ['en']\n",
            "thanda ['hi']\n",
            "\n",
            "after ['en']\n",
            "changing ['en']\n",
            "kapde ['hi']\n",
            "uske ['hi']\n",
            "baad ['en']\n",
            "turant ['hi']\n",
            "he ['en']\n",
            "slept ['en']\n",
            "\n",
            "what ['en']\n",
            "when ['en']\n",
            "how ['en']\n",
            "kyun ['en']\n",
            "kab ['en']\n",
            "which ['en']\n",
            "noorjahan ['hi']\n",
            "\n",
            "the ['en']\n",
            "last ['en']\n",
            "thing ['en']\n",
            "meri ['hi']\n",
            "zindagi ['en']\n",
            "mein ['en']\n",
            "is ['en']\n",
            "to ['en']\n",
            "live ['en']\n",
            "poora ['hi']\n",
            "\n",
            "kal ['en']\n",
            "mai ['en']\n",
            "movie ['en']\n",
            "dekhne ['hi']\n",
            "jaa ['hi']\n",
            "raha ['hi']\n",
            "hun ['en']\n",
            "what ['en']\n",
            "are ['en']\n",
            "the ['en']\n",
            "reviews ['en']\n",
            "\n",
            "isko ['hi']\n",
            "code ['en']\n",
            "mix ['en']\n",
            "vaakya ['hi']\n",
            "kehte ['hi']\n",
            "hai ['en']\n",
            "\n"
          ]
        }
      ],
      "source": [
        "sentences = [\n",
        "    \"mera naam is there he she hum humko\",\n",
        "    \"tera yours mine\",\n",
        "    \"why so cool thanda\",\n",
        "    \"after changing kapde uske baad turant he slept\",\n",
        "    \"what when how kyun kab which noorjahan\",\n",
        "    \"the last thing meri zindagi mein is to live poora\",\n",
        "    \"kal mai movie dekhne jaa raha hun what are the reviews\",\n",
        "    \"isko code mix vaakya kehte hai\"\n",
        "]\n",
        "\n",
        "for s in sentences:\n",
        "    for w in s.split():\n",
        "        data = cv.transform([w]).toarray()\n",
        "        output = model.predict(data)\n",
        "        print(w, output)\n",
        "    print('')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Training, testing and doing some predictions on SVM model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.994875\n"
          ]
        }
      ],
      "source": [
        "\n",
        "from sklearn import svm\n",
        "\n",
        "clf = svm.SVC()\n",
        "clf.fit(X_train,y_train)\n",
        "print(clf.score(X_test,y_test))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "mera ['hi']\n",
            "naam ['hi']\n",
            "is ['hi']\n",
            "there ['hi']\n",
            "he ['hi']\n",
            "she ['hi']\n",
            "hum ['hi']\n",
            "humko ['hi']\n",
            "\n",
            "tera ['hi']\n",
            "yours ['hi']\n",
            "mine ['hi']\n",
            "\n",
            "why ['hi']\n",
            "so ['hi']\n",
            "cool ['hi']\n",
            "thanda ['hi']\n",
            "\n",
            "after ['en']\n",
            "changing ['hi']\n",
            "kapde ['hi']\n",
            "uske ['hi']\n",
            "baad ['hi']\n",
            "turant ['hi']\n",
            "he ['hi']\n",
            "slept ['hi']\n",
            "\n",
            "what ['hi']\n",
            "when ['hi']\n",
            "how ['hi']\n",
            "kyun ['hi']\n",
            "kab ['hi']\n",
            "which ['hi']\n",
            "noorjahan ['hi']\n",
            "\n",
            "the ['en']\n",
            "last ['en']\n",
            "thing ['en']\n",
            "meri ['hi']\n",
            "zindagi ['hi']\n",
            "mein ['hi']\n",
            "is ['hi']\n",
            "to ['hi']\n",
            "live ['hi']\n",
            "poora ['hi']\n",
            "\n",
            "kal ['hi']\n",
            "mai ['hi']\n",
            "movie ['hi']\n",
            "dekhne ['hi']\n",
            "jaa ['hi']\n",
            "raha ['hi']\n",
            "hun ['hi']\n",
            "what ['hi']\n",
            "are ['en']\n",
            "the ['en']\n",
            "reviews ['hi']\n",
            "\n",
            "isko ['hi']\n",
            "code ['hi']\n",
            "mix ['hi']\n",
            "vaakya ['hi']\n",
            "kehte ['hi']\n",
            "hai ['hi']\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for s in sentences:\n",
        "    for w in s.split():\n",
        "        data = cv.transform([w]).toarray()\n",
        "        output = clf.predict(data)\n",
        "        print(w, output)\n",
        "    print('')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Getting in the real data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data_og = pd.read_csv('data_100k.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index(['idx', 'regno', 'name', 'state', 'gender', 'channel', 'source',\n",
              "       'district', 'regdate', 'receivedate', 'disposedate', 'closedate',\n",
              "       'category', 'pmocategory', 'description', 'rating', 'comments',\n",
              "       'finalreply', 'initforward', 'reminders', 'resolvetime', 'deo', 'freq',\n",
              "       'spam', 'pending', 'class', 'seen'],\n",
              "      dtype='object')"
            ]
          },
          "execution_count": 408,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data_og.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Sir mai virendra pratap singh uttar pradesh ka rahne wala hu sir mai  faridabad mai rent pr rahkr majdoori karta hu sir 02/12/2020 ko mr. Akram ke yaha kam karne ke liye labour chok se gay joki ghar ka saman shift karna tha jis ke majdoori maine rupay 20000(twntiy thousand rupay) tay ke the maine kiray pr truk our 4 labour kr maine kam kar diya saman shift diya tab maine rupay mage to Akram ki maa kahne lage yaha se bhagja nahi mai tujhe bahut maruge  mai mahila ayog ke member hu sir  esa kahetehuye akaram ne mujhe maa bahan galigaloj ke mai chala aya fir  mai 2days bad gaya to mujhe jan se marne ki dhamkedene lage our 3 other log bulaliye sir AKRAM B UNKE MAA kahne lage tu hamara kuch nahi kr paye bhag  ga sir mai majooro ko b truck wale ko rupay kaha se do sir uttar pradesh ke labour department mai ragisterd hu mera registration number UPBOCW 09170500087501 hai sir mai rent pr rehkr apna b apne pariwar ka majduri kr gujara karta hu sir Akaram ka mobile number 9599807071 hai sir yeh kam maine sector 8 faridabad se sector 9 faridabad Hariyana mai kiyatha sir mai kaye bar rupay magne gaya lakin mere sath marpet karne dhamke dete hai sir mere sath insaf kiya jaye b in logo ke sath kanoone kariyawahe karne ke kirpa kare'"
            ]
          },
          "execution_count": 413,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data_og.description[3]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting transliterate\n",
            "  Downloading transliterate-1.10.2-py2.py3-none-any.whl (45 kB)\n",
            "\u001b[K     |████████████████████████████████| 45 kB 95 kB/s eta 0:00:011\n",
            "\u001b[?25hRequirement already satisfied: six>=1.1.0 in /Users/joker/opt/anaconda3/lib/python3.9/site-packages (from transliterate) (1.16.0)\n",
            "Installing collected packages: transliterate\n",
            "Successfully installed transliterate-1.10.2\n"
          ]
        }
      ],
      "source": [
        "!pip install transliterate\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from transliterate import translit, get_available_language_codes\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "ename": "LanguageCodeError",
          "evalue": "``language_code`` is optional with ``reversed`` set to True only.",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mLanguageCodeError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/var/folders/6t/snv12c4s0z946pr0z8v_br280000gn/T/ipykernel_15711/663207631.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtranslit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'main'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/transliterate/utils.py\u001b[0m in \u001b[0;36mtranslit\u001b[0;34m(value, language_code, reversed, strict)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlanguage_code\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mreversed\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m         raise LanguageCodeError(\n\u001b[0m\u001b[1;32m     79\u001b[0m             _(\"``language_code`` is optional with ``reversed`` set to True \"\n\u001b[1;32m     80\u001b[0m               \"only.\")\n",
            "\u001b[0;31mLanguageCodeError\u001b[0m: ``language_code`` is optional with ``reversed`` set to True only."
          ]
        }
      ],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "Language detector.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
